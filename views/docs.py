# app_reurb_gemini.py
# Requisitos:
#   pip install streamlit google-genai pandas
# Execu√ß√£o:
#   export GEMINI_API_KEY="sua_chave"
#   streamlit run app_reurb_gemini.py

import os
import re
import json
import tempfile
from pathlib import Path
from collections import Counter
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from google import genai
from google.genai import types

# -----------------------------
# Configura√ß√£o inicial
# -----------------------------
st.set_page_config(page_title="REURB ‚Äî Analisador Gemini", page_icon="üèóÔ∏è", layout="wide")
st.title("üèóÔ∏è REURB ‚Äî Analisador de Documentos com Gemini")

# Configura√ß√£o da API key com tratamento de erro melhorado
try:
    API_KEY = os.getenv("GEMINI_API_KEY")
    if not API_KEY and "google_gemini" in st.secrets:
        API_KEY = st.secrets["google_gemini"]["GEMINI_API_KEY"]
    
    if not API_KEY:
        st.error("‚ö†Ô∏è Defina GEMINI_API_KEY no ambiente ou em st.secrets para continuar.")
        st.info("Para obter uma API key, acesse: https://makersuite.google.com/app/apikey")
        st.stop()
except Exception as e:
    st.error(f"Erro ao configurar API key: {str(e)}")
    st.stop()

# Inicializar cliente Gemini
try:
    client = genai.Client(api_key=API_KEY)
    GEMINI_MODEL = "gemini-2.0-flash-exp"  # Modelo mais atualizado
except Exception as e:
    st.error(f"Erro ao inicializar cliente Gemini: {str(e)}")
    st.stop()

# -----------------------------
# Prompt do modelo (jur√≠dico)
# -----------------------------
SYSTEM_PROMPT = """
Voc√™ √© um assistente jur√≠dico especializado em Regulariza√ß√£o Fundi√°ria Urbana (REURB) no Brasil.
Base normativa: Lei 13.465/2017 e Decreto 9.310/2018.

Tarefas:
1) Para CADA arquivo enviado, identificar o tipo de documento (ex.: RG, CPF, certid√£o, contrato, escritura,
   matr√≠cula, IPTU, carn√™, planta, memorial descritivo, ART/RRT, projeto urban√≠stico, requerimento, termo
   de compromisso, lista/qualifica√ß√£o de ocupantes, CRF, etc.), com confian√ßa 0‚Äì1.
2) Extrair campos-chave √∫teis (nome, CPF/CNPJ, endere√ßo, matr√≠cula/cart√≥rio, datas, n¬∫ de processo, munic√≠pio, etc.).
3) Indicar se √© RELEVANTE para REURB e por qu√™.
4) Considerando o conjunto, sugerir a MODALIDADE PROV√ÅVEL (REURB-S, REURB-E ou indeterminada)
   e LISTAR DOCUMENTOS PROVAVELMENTE FALTANTES, cada um com:
   - prioridade (alta/m√©dia/baixa),
   - por que √© necess√°rio,
   - base legal sucinta (art./¬ß da Lei 13.465/2017 ou Decreto 9.310/2018, quando aplic√°vel).

Responda ESTRITAMENTE em JSON v√°lido seguindo este schema:

{
  "files": [
    {
      "file_name": "string",
      "detected_type": "string", 
      "confidence": 0.0,
      "relevant_for_reurb": true,
      "key_fields": {},
      "notes": "string"
    }
  ],
  "likely_modality": "REURB-S" ou "REURB-E" ou null,
  "missing_documents": [
    {
      "name": "string",
      "why_needed": "string", 
      "legal_basis": "string ou null",
      "priority": "alta" ou "m√©dia" ou "baixa"
    }
  ]
}

Regras importantes:
- Se algo n√£o puder ser determinado, use null ou explique em "notes"
- N√£o escreva nada al√©m do JSON v√°lido
- Use apenas os valores exatos especificados para enums (REURB-S, REURB-E, alta, m√©dia, baixa)
"""

# -----------------------------
# Utilit√°rios
# -----------------------------
def _resp_to_text(resp) -> str:
    """Extrai texto da resposta do Gemini com m√∫ltiplas tentativas."""
    # Primeira tentativa: atributos diretos
    text = getattr(resp, "text", None)
    if text:
        return text.strip()
    
    # Segunda tentativa: candidates
    if hasattr(resp, "candidates") and resp.candidates:
        for candidate in resp.candidates:
            if hasattr(candidate, "content") and candidate.content:
                parts = getattr(candidate.content, "parts", [])
                text_parts = []
                for part in parts:
                    if hasattr(part, "text") and part.text:
                        text_parts.append(part.text)
                if text_parts:
                    return "\n".join(text_parts).strip()
    
    # Verificar bloqueios
    if hasattr(resp, "prompt_feedback"):
        pf = resp.prompt_feedback
        if hasattr(pf, "block_reason") and pf.block_reason:
            raise RuntimeError(f"Conte√∫do bloqueado pelo modelo: {pf.block_reason}")
    
    raise ValueError("Modelo n√£o retornou texto v√°lido para an√°lise.")

def _extract_json(text: str) -> dict:
    """
    Parser tolerante para JSON com m√∫ltiplas estrat√©gias.
    """
    if not text or not text.strip():
        raise ValueError("Resposta vazia do modelo.")

    text = text.strip()
    
    # Estrat√©gia 1: Bloco de c√≥digo JSON
    json_match = re.search(r"```json\s*(.*?)\s*```", text, flags=re.DOTALL | re.IGNORECASE)
    if json_match:
        try:
            return json.loads(json_match.group(1).strip())
        except json.JSONDecodeError as e:
            st.warning(f"Erro ao parsear JSON do bloco de c√≥digo: {e}")
    
    # Estrat√©gia 2: Buscar primeiro objeto JSON completo
    brace_count = 0
    start_idx = -1
    
    for i, char in enumerate(text):
        if char == '{':
            if start_idx == -1:
                start_idx = i
            brace_count += 1
        elif char == '}':
            brace_count -= 1
            if brace_count == 0 and start_idx != -1:
                try:
                    return json.loads(text[start_idx:i+1])
                except json.JSONDecodeError:
                    continue
    
    # Estrat√©gia 3: Tentativa direta
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        raise ValueError(f"N√£o foi poss√≠vel extrair JSON v√°lido da resposta. Erro: {e}\n\nTexto recebido: {text[:500]}...")

# Schema corrigido para o Gemini
REURB_SCHEMA = types.Schema(
    type=types.Type.OBJECT,
    required=["files", "missing_documents"],
    properties={
        "files": types.Schema(
            type=types.Type.ARRAY,
            items=types.Schema(
                type=types.Type.OBJECT,
                required=[
                    "file_name", "detected_type", "confidence",
                    "relevant_for_reurb", "key_fields", "notes"
                ],
                properties={
                    "file_name": types.Schema(type=types.Type.STRING),
                    "detected_type": types.Schema(type=types.Type.STRING),
                    "confidence": types.Schema(type=types.Type.NUMBER),
                    "relevant_for_reurb": types.Schema(type=types.Type.BOOLEAN),
                    "key_fields": types.Schema(
                        type=types.Type.OBJECT,
                        properties={
                            "nome": types.Schema(type=types.Type.STRING),
                            "cpf": types.Schema(type=types.Type.STRING),
                            "cnpj": types.Schema(type=types.Type.STRING),
                            "endereco": types.Schema(type=types.Type.STRING),
                            "matricula": types.Schema(type=types.Type.STRING),
                            "cartorio": types.Schema(type=types.Type.STRING),
                            "data": types.Schema(type=types.Type.STRING),
                            "numero_processo": types.Schema(type=types.Type.STRING),
                            "municipio": types.Schema(type=types.Type.STRING),
                            "area": types.Schema(type=types.Type.STRING),
                            "valor": types.Schema(type=types.Type.STRING),
                        },
                        additionalProperties=True
                    ),
                    "notes": types.Schema(type=types.Type.STRING),
                },
            ),
        ),
        "likely_modality": types.Schema(type=types.Type.STRING),
        "missing_documents": types.Schema(
            type=types.Type.ARRAY,
            items=types.Schema(
                type=types.Type.OBJECT,
                required=["name", "why_needed", "priority"],
                properties={
                    "name": types.Schema(type=types.Type.STRING),
                    "why_needed": types.Schema(type=types.Type.STRING),
                    "legal_basis": types.Schema(type=types.Type.STRING),
                    "priority": types.Schema(type=types.Type.STRING),
                },
            ),
        ),
    },
)

def _get_mime_type(filename: str) -> str:
    """Determina o MIME type baseado na extens√£o do arquivo."""
    ext = Path(filename).suffix.lower()
    mime_types = {
        '.pdf': 'application/pdf',
        '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        '.doc': 'application/msword',
        '.txt': 'text/plain',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
    }
    return mime_types.get(ext, 'application/octet-stream')

def _upload_files_to_gemini(uploaded_files) -> List[Any]:
    """Upload de arquivos para a Files API do Gemini com tratamento de erros."""
    refs = []
    progress_bar = st.progress(0, text="Enviando arquivos para o Gemini...")
    
    try:
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                mime_type = _get_mime_type(uploaded_file.name)
                st.info(f"Processando {uploaded_file.name} (MIME: {mime_type})")
                
                # Criar arquivo tempor√°rio
                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_path = Path(temp_dir) / uploaded_file.name
                    temp_path.write_bytes(uploaded_file.getvalue())
                    
                    # M√©todo baseado na documenta√ß√£o oficial do google-genai
                    try:
                        # Usar apenas argumentos nomeados conforme documenta√ß√£o
                        file_ref = client.files.upload(
                            path=str(temp_path)
                        )
                        st.success(f"‚úÖ Upload realizado com sucesso: {uploaded_file.name}")
                        
                    except Exception as e1:
                        st.warning(f"M√©todo 1 falhou: {e1}")
                        
                        # M√©todo alternativo: usando o objeto pathlib.Path
                        try:
                            file_ref = client.files.upload(path=temp_path)
                            st.success(f"‚úÖ Upload realizado (m√©todo 2): {uploaded_file.name}")
                            
                        except Exception as e2:
                            st.warning(f"M√©todo 2 falhou: {e2}")
                            
                            # M√©todo 3: for√ßar mime_type
                            try:
                                # Usar a API mais b√°sica poss√≠vel
                                import google.genai as genai_alt
                                genai_alt.configure(api_key=API_KEY)
                                file_ref = genai_alt.upload_file(str(temp_path))
                                st.success(f"‚úÖ Upload realizado (m√©todo 3): {uploaded_file.name}")
                                
                            except Exception as e3:
                                st.error(f"M√©todo 3 tamb√©m falhou: {e3}")
                                
                                # √öltima tentativa: importa√ß√£o alternativa
                                try:
                                    import google.generativeai as genai_old
                                    genai_old.configure(api_key=API_KEY)
                                    file_ref = genai_old.upload_file(str(temp_path))
                                    st.success(f"‚úÖ Upload realizado (m√©todo legacy): {uploaded_file.name}")
                                    
                                except Exception as e4:
                                    st.error(f"Todos os m√©todos falharam para {uploaded_file.name}")
                                    st.error(f"Erros: {e1}, {e2}, {e3}, {e4}")
                                    
                                    # Debug: mostrar a vers√£o da biblioteca
                                    try:
                                        import google.genai
                                        st.info(f"Vers√£o google-genai: {google.genai.__version__}")
                                    except:
                                        st.info("N√£o foi poss√≠vel determinar a vers√£o da biblioteca")
                                    
                                    raise Exception(f"Falha em todos os m√©todos de upload para {uploaded_file.name}")
                
                refs.append(file_ref)
                
                progress_bar.progress(
                    (i + 1) / len(uploaded_files), 
                    text=f"‚úÖ {uploaded_file.name} ({i+1}/{len(uploaded_files)})"
                )
                
            except Exception as e:
                st.error(f"Erro fatal ao enviar {uploaded_file.name}: {str(e)}")
                progress_bar.empty()
                raise
        
        progress_bar.empty()
        st.success(f"üéâ {len(refs)} arquivo(s) enviado(s) com sucesso!")
        return refs
        
    except Exception as e:
        progress_bar.empty()
        st.error(f"Erro durante upload: {str(e)}")
        raise

def _call_gemini(files_refs) -> dict:
    """
    Chamada ao modelo Gemini com configura√ß√£o robusta.
    """
    user_prompt = "Analise os documentos enviados conforme as instru√ß√µes do sistema e retorne apenas o JSON estruturado solicitado."
    
    try:
        # Primeira tentativa: com schema completo
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=[user_prompt] + files_refs,
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_PROMPT,
                response_mime_type="application/json",
                response_schema=REURB_SCHEMA,
                temperature=0.1,
                max_output_tokens=4096,
            ),
        )
        
        text = _resp_to_text(response)
        return _extract_json(text)
        
    except Exception as e:
        st.warning(f"Schema restritivo falhou: {str(e)}. Tentando sem schema...")
        
        # Segunda tentativa: apenas JSON sem schema
        try:
            response = client.models.generate_content(
                model=GEMINI_MODEL,
                contents=[user_prompt] + files_refs,
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    response_mime_type="application/json",
                    temperature=0.1,
                    max_output_tokens=4096,
                ),
            )
            
            text = _resp_to_text(response)
            return _extract_json(text)
            
        except Exception as e2:
            st.warning(f"JSON sem schema falhou: {str(e2)}. Tentando texto livre...")
            
            # Terceira tentativa: texto livre
            try:
                response = client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=[user_prompt] + files_refs,
                    config=types.GenerateContentConfig(
                        system_instruction=SYSTEM_PROMPT,
                        temperature=0.1,
                        max_output_tokens=4096,
                    ),
                )
                
                text = _resp_to_text(response)
                return _extract_json(text)
                
            except Exception as e3:
                st.error(f"Todas as tentativas falharam. √öltimo erro: {str(e3)}")
                raise e3

def _build_dashboard(payload: Dict[str, Any]):
    """Constr√≥i o dashboard de an√°lise."""
    files = payload.get("files", [])
    missing = payload.get("missing_documents", [])
    likely_modality = payload.get("likely_modality")

    # M√©tricas principais
    total_files = len(files)
    relevant_files = sum(1 for f in files if f.get("relevant_for_reurb", False))
    
    st.subheader("üìä Resumo da An√°lise")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Arquivos analisados", total_files)
    with col2:
        st.metric("Relevantes p/ REURB", relevant_files)
    with col3:
        st.metric("N√£o relevantes", total_files - relevant_files)
    with col4:
        st.metric("Documentos faltantes", len(missing))

    # Distribui√ß√£o por tipo
    if files:
        type_counts = Counter([f.get("detected_type", "Indefinido") for f in files])
        type_df = pd.DataFrame({
            "Tipo": list(type_counts.keys()), 
            "Quantidade": list(type_counts.values())
        }).sort_values("Quantidade", ascending=False)
        
        st.subheader("üìà Distribui√ß√£o por Tipo de Documento")
        st.bar_chart(type_df.set_index("Tipo"))

    # Tabs organizadas
    tab_files, tab_missing, tab_summary, tab_raw = st.tabs([
        "üìÑ Arquivos Analisados", 
        "üìã Documentos Faltantes", 
        "üìù Resumo Executivo",
        "üîß Dados Brutos"
    ])

    # Tab: Arquivos analisados
    with tab_files:
        if not files:
            st.info("Nenhum arquivo foi analisado.")
        else:
            df = pd.DataFrame(files)
            
            # Prepara√ß√£o dos dados para exibi√ß√£o
            df["confidence_pct"] = (df.get("confidence", 0.0) * 100).round(1)
            df["relevante"] = df.get("relevant_for_reurb", False)
            df["tipo"] = df.get("detected_type", "Indefinido")
            df["arquivo"] = df.get("file_name", "Sem nome")
            df["notas"] = df.get("notes", "")

            # Filtros
            col1, col2 = st.columns(2)
            with col1:
                relevance_filter = st.selectbox(
                    "Filtrar por relev√¢ncia:",
                    ["Todos", "Apenas relevantes", "Apenas n√£o relevantes"]
                )
            with col2:
                available_types = sorted(df["tipo"].unique())
                selected_types = st.multiselect(
                    "Tipos de documento:", 
                    available_types, 
                    default=available_types
                )

            # Aplicar filtros
            filtered_df = df[df["tipo"].isin(selected_types)]
            if relevance_filter == "Apenas relevantes":
                filtered_df = filtered_df[filtered_df["relevante"] == True]
            elif relevance_filter == "Apenas n√£o relevantes":
                filtered_df = filtered_df[filtered_df["relevante"] == False]

            # Exibir tabela
            display_df = filtered_df[["arquivo", "tipo", "confidence_pct", "relevante", "notas"]].copy()
            
            st.dataframe(
                display_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "arquivo": st.column_config.TextColumn("Arquivo"),
                    "tipo": st.column_config.TextColumn("Tipo"),
                    "confidence_pct": st.column_config.ProgressColumn(
                        "Confian√ßa (%)", 
                        min_value=0, 
                        max_value=100,
                        format="%.1f%%"
                    ),
                    "relevante": st.column_config.CheckboxColumn("Relevante"),
                    "notas": st.column_config.TextColumn("Observa√ß√µes"),
                }
            )

            # Campos extra√≠dos
            if st.expander("üîç Ver campos extra√≠dos por arquivo"):
                for _, row in filtered_df.iterrows():
                    key_fields = row.get("key_fields", {})
                    if key_fields:
                        st.subheader(row["arquivo"])
                        st.json(key_fields)

    # Tab: Documentos faltantes
    with tab_missing:
        if likely_modality:
            st.info(f"**Modalidade prov√°vel:** {likely_modality}")
        
        if not missing:
            st.success("‚úÖ Nenhum documento faltante identificado pelo modelo.")
        else:
            st.subheader(f"üìã {len(missing)} documento(s) faltante(s) identificado(s)")
            
            missing_df = pd.DataFrame(missing)
            
            # Mapeamento de prioridades com √≠cones
            priority_mapping = {
                "alta": "üî¥ Alta",
                "m√©dia": "üü° M√©dia", 
                "media": "üü° M√©dia",
                "baixa": "üü¢ Baixa"
            }
            
            missing_df["priority_display"] = missing_df.get("priority", "").str.lower().map(priority_mapping).fillna("‚ö™ Indefinida")
            missing_df["legal_basis"] = missing_df.get("legal_basis", "").fillna("N/A")
            
            # Filtro por prioridade
            available_priorities = sorted(missing_df["priority_display"].unique())
            selected_priorities = st.multiselect(
                "Filtrar por prioridade:",
                available_priorities,
                default=available_priorities
            )
            
            filtered_missing = missing_df[missing_df["priority_display"].isin(selected_priorities)]
            
            # Exibir tabela
            display_missing = filtered_missing[[
                "name", "priority_display", "legal_basis", "why_needed"
            ]].rename(columns={
                "name": "Documento",
                "priority_display": "Prioridade", 
                "legal_basis": "Base Legal",
                "why_needed": "Justificativa"
            })
            
            st.dataframe(
                display_missing,
                use_container_width=True,
                hide_index=True
            )

    # Tab: Resumo executivo
    with tab_summary:
        st.subheader("üìù Resumo Executivo")
        
        # Status geral
        if likely_modality:
            st.success(f"**Modalidade REURB identificada:** {likely_modality}")
        else:
            st.warning("**Modalidade REURB:** Indeterminada com base nos documentos enviados")
        
        # An√°lise de completude
        completeness = (relevant_files / max(total_files, 1)) * 100
        if completeness >= 80:
            st.success(f"**Completude documental:** {completeness:.1f}% - Boa cobertura")
        elif completeness >= 60:
            st.warning(f"**Completude documental:** {completeness:.1f}% - Cobertura adequada")
        else:
            st.error(f"**Completude documental:** {completeness:.1f}% - Documenta√ß√£o insuficiente")
        
        # Pr√≥ximos passos
        st.subheader("üéØ Pr√≥ximos Passos Recomendados")
        if missing:
            high_priority = [doc for doc in missing if doc.get("priority", "").lower() == "alta"]
            if high_priority:
                st.error(f"**Urgente:** {len(high_priority)} documento(s) de alta prioridade faltando")
                for doc in high_priority:
                    st.write(f"‚Ä¢ **{doc['name']}**: {doc['why_needed']}")
        else:
            st.success("**Documenta√ß√£o aparenta estar completa** para prosseguir com o processo REURB")

    # Tab: Dados brutos
    with tab_raw:
        st.subheader("üîß JSON Bruto da An√°lise")
        st.json(payload, expanded=False)
        
        # Download do JSON
        json_str = json.dumps(payload, ensure_ascii=False, indent=2)
        st.download_button(
            label="üì• Baixar an√°lise completa (JSON)",
            data=json_str.encode("utf-8"),
            file_name="reurb_analise_completa.json",
            mime="application/json"
        )

# -----------------------------
# Interface Principal
# -----------------------------
st.markdown("---")
st.subheader("üì§ Upload de Documentos")

st.info(
    "üìã **Tipos suportados:** PDF e DOCX  \n"
    "üîê **Privacidade:** Arquivos s√£o enviados temporariamente para an√°lise e n√£o s√£o armazenados permanentemente  \n"
    "‚ö° **Processamento:** An√°lise automatizada via IA especializada em REURB"
)

uploaded_files = st.file_uploader(
    "Selecione os documentos para an√°lise:",
    type=["pdf", "docx"],
    accept_multiple_files=True,
    help="Envie documentos relacionados ao processo REURB (RG, CPF, escrituras, plantas, etc.)"
)

if uploaded_files:
    st.success(f"‚úÖ {len(uploaded_files)} arquivo(s) carregado(s)")
    
    # Mostrar lista de arquivos
    with st.expander("üìÅ Arquivos carregados"):
        for i, file in enumerate(uploaded_files, 1):
            file_size = len(file.getvalue()) / 1024  # KB
            st.write(f"{i}. **{file.name}** ({file_size:.1f} KB)")
    
    # Bot√£o de an√°lise
    if st.button("üöÄ Iniciar An√°lise", type="primary", use_container_width=True):
        try:
            # Upload para Gemini
            with st.status("üì§ Enviando arquivos para an√°lise...", expanded=True) as status:
                file_refs = _upload_files_to_gemini(uploaded_files)
                status.update(label="‚úÖ Upload conclu√≠do", state="complete")
            
            # An√°lise
            with st.status("üß† Analisando documentos com IA...", expanded=True) as status:
                analysis_result = _call_gemini(file_refs)
                status.update(label="‚úÖ An√°lise conclu√≠da", state="complete")
            
            # Salvar na sess√£o e exibir
            st.session_state["reurb_analysis"] = analysis_result
            st.success("üéâ An√°lise conclu√≠da com sucesso! Veja os resultados abaixo.")
            st.balloons()
            
        except Exception as e:
            st.error("‚ùå Erro durante a an√°lise:")
            st.exception(e)

else:
    st.info("‚¨ÜÔ∏è Fa√ßa upload dos documentos para come√ßar a an√°lise")

# Exibir dashboard se houver an√°lise
if "reurb_analysis" in st.session_state:
    st.markdown("---")
    _build_dashboard(st.session_state["reurb_analysis"])

# Rodap√©
st.markdown("---")
st.caption(
    "üèóÔ∏è **REURB Analyzer** - Ferramenta de an√°lise documental para Regulariza√ß√£o Fundi√°ria Urbana  \n"
    "‚öñÔ∏è Base legal: Lei 13.465/2017 e Decreto 9.310/2018  \n"
    "ü§ñ Powered by Google Gemini AI"
)