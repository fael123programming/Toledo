# app_reurb_gemini.py
# Requisitos:
#   pip install streamlit google-genai pandas
# ExecuÃ§Ã£o:
#   export GEMINI_API_KEY="sua_chave"
#   streamlit run app_reurb_gemini.py

import os
import re
import json
import tempfile
from pathlib import Path
from collections import Counter
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from google import genai
from google.genai import types

# -----------------------------
# ConfiguraÃ§Ã£o inicial
# -----------------------------
st.set_page_config(page_title="REURB â€” Analisador Gemini", page_icon="ğŸ—ï¸", layout="wide")
st.title("ğŸ—ï¸ REURB â€” Analisador de Documentos com Gemini")

# ConfiguraÃ§Ã£o da API key com tratamento de erro melhorado
try:
    API_KEY = os.getenv("GEMINI_API_KEY")
    if not API_KEY and "google_gemini" in st.secrets:
        API_KEY = st.secrets["google_gemini"]["GEMINI_API_KEY"]
    
    if not API_KEY:
        st.error("âš ï¸ Defina GEMINI_API_KEY no ambiente ou em st.secrets para continuar.")
        st.info("Para obter uma API key, acesse: https://makersuite.google.com/app/apikey")
        st.stop()
except Exception as e:
    st.error(f"Erro ao configurar API key: {str(e)}")
    st.stop()

# Inicializar cliente Gemini
try:
    client = genai.Client(api_key=API_KEY)
    GEMINI_MODEL = "gemini-2.0-flash-exp"  # Modelo mais atualizado
except Exception as e:
    st.error(f"Erro ao inicializar cliente Gemini: {str(e)}")
    st.stop()

# -----------------------------
# Prompt do modelo (jurÃ­dico)
# -----------------------------
SYSTEM_PROMPT = """
VocÃª Ã© um assistente jurÃ­dico especializado em RegularizaÃ§Ã£o FundiÃ¡ria Urbana (REURB) no Brasil.
Base normativa: Lei 13.465/2017 e Decreto 9.310/2018.

Tarefas:
1) Para CADA arquivo enviado, identificar o tipo de documento (ex.: RG, CPF, certidÃ£o, contrato, escritura,
   matrÃ­cula, IPTU, carnÃª, planta, memorial descritivo, ART/RRT, projeto urbanÃ­stico, requerimento, termo
   de compromisso, lista/qualificaÃ§Ã£o de ocupantes, CRF, etc.), com confianÃ§a 0â€“1.
2) Extrair campos-chave Ãºteis (nome, CPF/CNPJ, endereÃ§o, matrÃ­cula/cartÃ³rio, datas, nÂº de processo, municÃ­pio, etc.).
3) Indicar se Ã© RELEVANTE para REURB e por quÃª.
4) Considerando o conjunto, sugerir a MODALIDADE PROVÃVEL (REURB-S, REURB-E ou indeterminada)
   e LISTAR DOCUMENTOS PROVAVELMENTE FALTANTES, cada um com:
   - prioridade (alta/mÃ©dia/baixa),
   - por que Ã© necessÃ¡rio,
   - base legal sucinta (art./Â§ da Lei 13.465/2017 ou Decreto 9.310/2018, quando aplicÃ¡vel).

Responda ESTRITAMENTE em JSON vÃ¡lido seguindo este schema:

{
  "files": [
    {
      "file_name": "string",
      "detected_type": "string", 
      "confidence": 0.0,
      "relevant_for_reurb": true,
      "key_fields": {},
      "notes": "string"
    }
  ],
  "likely_modality": "REURB-S" ou "REURB-E" ou null,
  "missing_documents": [
    {
      "name": "string",
      "why_needed": "string", 
      "legal_basis": "string ou null",
      "priority": "alta" ou "mÃ©dia" ou "baixa"
    }
  ]
}

Regras importantes:
- Se algo nÃ£o puder ser determinado, use null ou explique em "notes"
- NÃ£o escreva nada alÃ©m do JSON vÃ¡lido
- Use apenas os valores exatos especificados para enums (REURB-S, REURB-E, alta, mÃ©dia, baixa)
"""

# -----------------------------
# UtilitÃ¡rios
# -----------------------------
def _resp_to_text(resp) -> str:
    """Extrai texto da resposta do Gemini com mÃºltiplas tentativas."""
    # Primeira tentativa: atributos diretos
    text = getattr(resp, "text", None)
    if text:
        return text.strip()
    
    # Segunda tentativa: candidates
    if hasattr(resp, "candidates") and resp.candidates:
        for candidate in resp.candidates:
            if hasattr(candidate, "content") and candidate.content:
                parts = getattr(candidate.content, "parts", [])
                text_parts = []
                for part in parts:
                    if hasattr(part, "text") and part.text:
                        text_parts.append(part.text)
                if text_parts:
                    return "\n".join(text_parts).strip()
    
    # Verificar bloqueios
    if hasattr(resp, "prompt_feedback"):
        pf = resp.prompt_feedback
        if hasattr(pf, "block_reason") and pf.block_reason:
            raise RuntimeError(f"ConteÃºdo bloqueado pelo modelo: {pf.block_reason}")
    
    raise ValueError("Modelo nÃ£o retornou texto vÃ¡lido para anÃ¡lise.")

def _extract_json(text: str) -> dict:
    """
    Parser tolerante para JSON com mÃºltiplas estratÃ©gias.
    """
    if not text or not text.strip():
        raise ValueError("Resposta vazia do modelo.")

    text = text.strip()
    
    # EstratÃ©gia 1: Bloco de cÃ³digo JSON
    json_match = re.search(r"```json\s*(.*?)\s*```", text, flags=re.DOTALL | re.IGNORECASE)
    if json_match:
        try:
            return json.loads(json_match.group(1).strip())
        except json.JSONDecodeError as e:
            st.warning(f"Erro ao parsear JSON do bloco de cÃ³digo: {e}")
    
    # EstratÃ©gia 2: Buscar primeiro objeto JSON completo
    brace_count = 0
    start_idx = -1
    
    for i, char in enumerate(text):
        if char == '{':
            if start_idx == -1:
                start_idx = i
            brace_count += 1
        elif char == '}':
            brace_count -= 1
            if brace_count == 0 and start_idx != -1:
                try:
                    return json.loads(text[start_idx:i+1])
                except json.JSONDecodeError:
                    continue
    
    # EstratÃ©gia 3: Tentativa direta
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        raise ValueError(f"NÃ£o foi possÃ­vel extrair JSON vÃ¡lido da resposta. Erro: {e}\n\nTexto recebido: {text[:500]}...")

# Schema corrigido para o Gemini
REURB_SCHEMA = types.Schema(
    type=types.Type.OBJECT,
    required=["files", "missing_documents"],
    properties={
        "files": types.Schema(
            type=types.Type.ARRAY,
            items=types.Schema(
                type=types.Type.OBJECT,
                required=[
                    "file_name", "detected_type", "confidence",
                    "relevant_for_reurb", "key_fields", "notes"
                ],
                properties={
                    "file_name": types.Schema(type=types.Type.STRING),
                    "detected_type": types.Schema(type=types.Type.STRING),
                    "confidence": types.Schema(type=types.Type.NUMBER),
                    "relevant_for_reurb": types.Schema(type=types.Type.BOOLEAN),
                    "key_fields": types.Schema(
                        type=types.Type.OBJECT,
                        properties={
                            "nome": types.Schema(type=types.Type.STRING),
                            "cpf": types.Schema(type=types.Type.STRING),
                            "cnpj": types.Schema(type=types.Type.STRING),
                            "endereco": types.Schema(type=types.Type.STRING),
                            "matricula": types.Schema(type=types.Type.STRING),
                            "cartorio": types.Schema(type=types.Type.STRING),
                            "data": types.Schema(type=types.Type.STRING),
                            "numero_processo": types.Schema(type=types.Type.STRING),
                            "municipio": types.Schema(type=types.Type.STRING),
                            "area": types.Schema(type=types.Type.STRING),
                            "valor": types.Schema(type=types.Type.STRING),
                        },
                        additionalProperties=True
                    ),
                    "notes": types.Schema(type=types.Type.STRING),
                },
            ),
        ),
        "likely_modality": types.Schema(type=types.Type.STRING),
        "missing_documents": types.Schema(
            type=types.Type.ARRAY,
            items=types.Schema(
                type=types.Type.OBJECT,
                required=["name", "why_needed", "priority"],
                properties={
                    "name": types.Schema(type=types.Type.STRING),
                    "why_needed": types.Schema(type=types.Type.STRING),
                    "legal_basis": types.Schema(type=types.Type.STRING),
                    "priority": types.Schema(type=types.Type.STRING),
                },
            ),
        ),
    },
)

def _get_mime_type(filename: str) -> str:
    """Determina o MIME type baseado na extensÃ£o do arquivo."""
    ext = Path(filename).suffix.lower()
    mime_types = {
        '.pdf': 'application/pdf',
        '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        '.doc': 'application/msword',
        '.txt': 'text/plain',
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
    }
    return mime_types.get(ext, 'application/octet-stream')

def _upload_files_to_gemini(uploaded_files) -> List[Any]:
    """Upload de arquivos para a Files API do Gemini com tratamento de erros."""
    refs = []
    progress_bar = st.progress(0, text="Enviando arquivos para o Gemini...")
    
    try:
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                mime_type = _get_mime_type(uploaded_file.name)
                st.info(f"Processando {uploaded_file.name} (MIME: {mime_type})")
                
                # Criar arquivo temporÃ¡rio
                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_path = Path(temp_dir) / uploaded_file.name
                    temp_path.write_bytes(uploaded_file.getvalue())
                    
                    # MÃ©todo baseado na documentaÃ§Ã£o oficial do google-genai
                    try:
                        # Usar apenas argumentos nomeados conforme documentaÃ§Ã£o
                        file_ref = client.files.upload(
                            path=str(temp_path)
                        )
                        st.success(f"âœ… Upload realizado com sucesso: {uploaded_file.name}")
                        
                    except Exception as e1:
                        st.warning(f"MÃ©todo 1 falhou: {e1}")
                        
                        # MÃ©todo alternativo: usando o objeto pathlib.Path
                        try:
                            file_ref = client.files.upload(path=temp_path)
                            st.success(f"âœ… Upload realizado (mÃ©todo 2): {uploaded_file.name}")
                            
                        except Exception as e2:
                            st.warning(f"MÃ©todo 2 falhou: {e2}")
                            
                            # MÃ©todo 3: forÃ§ar mime_type
                            try:
                                # Usar a API mais bÃ¡sica possÃ­vel
                                import google.genai as genai_alt
                                genai_alt.configure(api_key=API_KEY)
                                file_ref = genai_alt.upload_file(str(temp_path))
                                st.success(f"âœ… Upload realizado (mÃ©todo 3): {uploaded_file.name}")
                                
                            except Exception as e3:
                                st.error(f"MÃ©todo 3 tambÃ©m falhou: {e3}")
                                
                                # Ãšltima tentativa: importaÃ§Ã£o alternativa
                                try:
                                    import google.generativeai as genai_old
                                    genai_old.configure(api_key=API_KEY)
                                    file_ref = genai_old.upload_file(str(temp_path))
                                    st.success(f"âœ… Upload realizado (mÃ©todo legacy): {uploaded_file.name}")
                                    
                                except Exception as e4:
                                    st.error(f"Todos os mÃ©todos falharam para {uploaded_file.name}")
                                    st.error(f"Erros: {e1}, {e2}, {e3}, {e4}")
                                    
                                    # Debug: mostrar a versÃ£o da biblioteca
                                    try:
                                        import google.genai
                                        st.info(f"VersÃ£o google-genai: {google.genai.__version__}")
                                    except:
                                        st.info("NÃ£o foi possÃ­vel determinar a versÃ£o da biblioteca")
                                    
                                    raise Exception(f"Falha em todos os mÃ©todos de upload para {uploaded_file.name}")
                
                refs.append(file_ref)
                
                progress_bar.progress(
                    (i + 1) / len(uploaded_files), 
                    text=f"âœ… {uploaded_file.name} ({i+1}/{len(uploaded_files)})"
                )
                
            except Exception as e:
                st.error(f"Erro fatal ao enviar {uploaded_file.name}: {str(e)}")
                progress_bar.empty()
                raise
        
        progress_bar.empty()
        st.success(f"ğŸ‰ {len(refs)} arquivo(s) enviado(s) com sucesso!")
        return refs
        
    except Exception as e:
        progress_bar.empty()
        st.error(f"Erro durante upload: {str(e)}")
        raise

def _call_gemini(files_refs) -> dict:
    """
    Chamada ao modelo Gemini com configuraÃ§Ã£o robusta.
    """
    user_prompt = "Analise os documentos enviados conforme as instruÃ§Ãµes do sistema e retorne apenas o JSON estruturado solicitado."
    
    try:
        # Primeira tentativa: com schema completo
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=[user_prompt] + files_refs,
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_PROMPT,
                response_mime_type="application/json",
                response_schema=REURB_SCHEMA,
                temperature=0.1,
                max_output_tokens=4096,
            ),
        )
        
        text = _resp_to_text(response)
        return _extract_json(text)
        
    except Exception as e:
        st.warning(f"Schema restritivo falhou: {str(e)}. Tentando sem schema...")
        
        # Segunda tentativa: apenas JSON sem schema
        try:
            response = client.models.generate_content(
                model=GEMINI_MODEL,
                contents=[user_prompt] + files_refs,
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT,
                    response_mime_type="application/json",
                    temperature=0.1,
                    max_output_tokens=4096,
                ),
            )
            
            text = _resp_to_text(response)
            return _extract_json(text)
            
        except Exception as e2:
            st.warning(f"JSON sem schema falhou: {str(e2)}. Tentando texto livre...")
            
            # Terceira tentativa: texto livre
            try:
                response = client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=[user_prompt] + files_refs,
                    config=types.GenerateContentConfig(
                        system_instruction=SYSTEM_PROMPT,
                        temperature=0.1,
                        max_output_tokens=4096,
                    ),
                )
                
                text = _resp_to_text(response)
                return _extract_json(text)
                
            except Exception as e3:
                st.error(f"Todas as tentativas falharam. Ãšltimo erro: {str(e3)}")
                raise e3

def _build_dashboard(payload: Dict[str, Any]):
    """ConstrÃ³i o dashboard de anÃ¡lise."""
    files = payload.get("files", [])
    missing = payload.get("missing_documents", [])
    likely_modality = payload.get("likely_modality")

    # MÃ©tricas principais
    total_files = len(files)
    relevant_files = sum(1 for f in files if f.get("relevant_for_reurb", False))
    
    st.subheader("ğŸ“Š Resumo da AnÃ¡lise")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Arquivos analisados", total_files)
    with col2:
        st.metric("Relevantes p/ REURB", relevant_files)
    with col3:
        st.metric("NÃ£o relevantes", total_files - relevant_files)
    with col4:
        st.metric("Documentos faltantes", len(missing))

    # DistribuiÃ§Ã£o por tipo
    if files:
        type_counts = Counter([f.get("detected_type", "Indefinido") for f in files])
        type_df = pd.DataFrame({
            "Tipo": list(type_counts.keys()), 
            "Quantidade": list(type_counts.values())
        }).sort_values("Quantidade", ascending=False)
        
        st.subheader("ğŸ“ˆ DistribuiÃ§Ã£o por Tipo de Documento")
        st.bar_chart(type_df.set_index("Tipo"))

    # Tabs organizadas
    tab_files, tab_missing, tab_summary, tab_raw = st.tabs([
        "ğŸ“„ Arquivos Analisados", 
        "ğŸ“‹ Documentos Faltantes", 
        "ğŸ“ Resumo Executivo",
        "ğŸ”§ Dados Brutos"
    ])

    # Tab: Arquivos analisados
    with tab_files:
        if not files:
            st.info("Nenhum arquivo foi analisado.")
        else:
            df = pd.DataFrame(files)
            
            # PreparaÃ§Ã£o dos dados para exibiÃ§Ã£o
            df["confidence_pct"] = (df.get("confidence", 0.0) * 100).round(1)
            df["relevante"] = df.get("relevant_for_reurb", False)
            df["tipo"] = df.get("detected_type", "Indefinido")
            df["arquivo"] = df.get("file_name", "Sem nome")
            df["notas"] = df.get("notes", "")

            # Filtros
            col1, col2 = st.columns(2)
            with col1:
                relevance_filter = st.selectbox(
                    "Filtrar por relevÃ¢ncia:",
                    ["Todos", "Apenas relevantes", "Apenas nÃ£o relevantes"]
                )
            with col2:
                available_types = sorted(df["tipo"].unique())
                selected_types = st.multiselect(
                    "Tipos de documento:", 
                    available_types, 
                    default=available_types
                )

            # Aplicar filtros
            filtered_df = df[df["tipo"].isin(selected_types)]
            if relevance_filter == "Apenas relevantes":
                filtered_df = filtered_df[filtered_df["relevante"] == True]
            elif relevance_filter == "Apenas nÃ£o relevantes":
                filtered_df = filtered_df[filtered_df["relevante"] == False]

            # Exibir tabela
            display_df = filtered_df[["arquivo", "tipo", "confidence_pct", "relevante", "notas"]].copy()
            
            st.dataframe(
                display_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "arquivo": st.column_config.TextColumn("Arquivo"),
                    "tipo": st.column_config.TextColumn("Tipo"),
                    "confidence_pct": st.column_config.ProgressColumn(
                        "ConfianÃ§a (%)", 
                        min_value=0, 
                        max_value=100,
                        format="%.1f%%"
                    ),
                    "relevante": st.column_config.CheckboxColumn("Relevante"),
                    "notas": st.column_config.TextColumn("ObservaÃ§Ãµes"),
                }
            )

            # Campos extraÃ­dos
            if st.expander("ğŸ” Ver campos extraÃ­dos por arquivo"):
                for _, row in filtered_df.iterrows():
                    key_fields = row.get("key_fields", {})
                    if key_fields:
                        st.subheader(row["arquivo"])
                        st.json(key_fields)

    # Tab: Documentos faltantes
    with tab_missing:
        if likely_modality:
            st.info(f"**Modalidade provÃ¡vel:** {likely_modality}")
        
        if not missing:
            st.success("âœ… Nenhum documento faltante identificado pelo modelo.")
        else:
            st.subheader(f"ğŸ“‹ {len(missing)} documento(s) faltante(s) identificado(s)")
            
            missing_df = pd.DataFrame(missing)
            
            # Mapeamento de prioridades com Ã­cones
            priority_mapping = {
                "alta": "ğŸ”´ Alta",
                "mÃ©dia": "ğŸŸ¡ MÃ©dia", 
                "media": "ğŸŸ¡ MÃ©dia",
                "baixa": "ğŸŸ¢ Baixa"
            }
            
            missing_df["priority_display"] = missing_df.get("priority", "").str.lower().map(priority_mapping).fillna("âšª Indefinida")
            missing_df["legal_basis"] = missing_df.get("legal_basis", "").fillna("N/A")
            
            # Filtro por prioridade
            available_priorities = sorted(missing_df["priority_display"].unique())
            selected_priorities = st.multiselect(
                "Filtrar por prioridade:",
                available_priorities,
                default=available_priorities
            )
            
            filtered_missing = missing_df[missing_df["priority_display"].isin(selected_priorities)]
            
            # Exibir tabela
            display_missing = filtered_missing[[
                "name", "priority_display", "legal_basis", "why_needed"
            ]].rename(columns={
                "name": "Documento",
                "priority_display": "Prioridade", 
                "legal_basis": "Base Legal",
                "why_needed": "Justificativa"
            })
            
            st.dataframe(
                display_missing,
                use_container_width=True,
                hide_index=True
            )

    # Tab: Resumo executivo
    with tab_summary:
        st.subheader("ğŸ“ Resumo Executivo")
        
        # Status geral
        if likely_modality:
            st.success(f"**Modalidade REURB identificada:** {likely_modality}")
        else:
            st.warning("**Modalidade REURB:** Indeterminada com base nos documentos enviados")
        
        # AnÃ¡lise de completude
        completeness = (relevant_files / max(total_files, 1)) * 100
        if completeness >= 80:
            st.success(f"**Completude documental:** {completeness:.1f}% - Boa cobertura")
        elif completeness >= 60:
            st.warning(f"**Completude documental:** {completeness:.1f}% - Cobertura adequada")
        else:
            st.error(f"**Completude documental:** {completeness:.1f}% - DocumentaÃ§Ã£o insuficiente")
        
        # PrÃ³ximos passos
        st.subheader("ğŸ¯ PrÃ³ximos Passos Recomendados")
        if missing:
            high_priority = [doc for doc in missing if doc.get("priority", "").lower() == "alta"]
            if high_priority:
                st.error(f"**Urgente:** {len(high_priority)} documento(s) de alta prioridade faltando")
                for doc in high_priority:
                    st.write(f"â€¢ **{doc['name']}**: {doc['why_needed']}")
        else:
            st.success("**DocumentaÃ§Ã£o aparenta estar completa** para prosseguir com o processo REURB")

    # Tab: Dados brutos
    with tab_raw:
        st.subheader("ğŸ”§ JSON Bruto da AnÃ¡lise")
        st.json(payload, expanded=False)
        
        # Download do JSON
        json_str = json.dumps(payload, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ Baixar anÃ¡lise completa (JSON)",
            data=json_str.encode("utf-8"),
            file_name="reurb_analise_completa.json",
            mime="application/json"
        )

# -----------------------------
# Interface Principal
# -----------------------------
st.markdown("---")
st.subheader("ğŸ“¤ Upload de Documentos")

st.info(
    "ğŸ“‹ **Tipos suportados:** PDF e DOCX  \n"
    "ğŸ” **Privacidade:** Arquivos sÃ£o enviados temporariamente para anÃ¡lise e nÃ£o sÃ£o armazenados permanentemente  \n"
    "âš¡ **Processamento:** AnÃ¡lise automatizada via IA especializada em REURB"
)

uploaded_files = st.file_uploader(
    "Selecione os documentos para anÃ¡lise:",
    type=["pdf", "docx"],
    accept_multiple_files=True,
    help="Envie documentos relacionados ao processo REURB (RG, CPF, escrituras, plantas, etc.)"
)

if uploaded_files:
    st.success(f"âœ… {len(uploaded_files)} arquivo(s) carregado(s)")
    
    # Mostrar lista de arquivos
    with st.expander("ğŸ“ Arquivos carregados"):
        for i, file in enumerate(uploaded_files, 1):
            file_size = len(file.getvalue()) / 1024  # KB
            st.write(f"{i}. **{file.name}** ({file_size:.1f} KB)")
    
    # BotÃ£o de anÃ¡lise
    if st.button("ğŸš€ Iniciar AnÃ¡lise", type="primary", use_container_width=True):
        try:
            # Upload para Gemini
            with st.status("ğŸ“¤ Enviando arquivos para anÃ¡lise...", expanded=True) as status:
                file_refs = _upload_files_to_gemini(uploaded_files)
                status.update(label="âœ… Upload concluÃ­do", state="complete")
            
            # AnÃ¡lise
            with st.status("ğŸ§  Analisando documentos com IA...", expanded=True) as status:
                analysis_result = _call_gemini(file_refs)
                status.update(label="âœ… AnÃ¡lise concluÃ­da", state="complete")
            
            # Salvar na sessÃ£o e exibir
            st.session_state["reurb_analysis"] = analysis_result
            st.success("ğŸ‰ AnÃ¡lise concluÃ­da com sucesso! Veja os resultados abaixo.")
            st.balloons()
            
        except Exception as e:
            st.error("âŒ Erro durante a anÃ¡lise:")
            st.exception(e)

else:
    st.info("â¬†ï¸ FaÃ§a upload dos documentos para comeÃ§ar a anÃ¡lise")

# Exibir dashboard se houver anÃ¡lise
if "reurb_analysis" in st.session_state:
    st.markdown("---")
    _build_dashboard(st.session_state["reurb_analysis"])

# RodapÃ©
st.markdown("---")
st.caption(
    "ğŸ—ï¸ **REURB Analyzer** - Ferramenta de anÃ¡lise documental para RegularizaÃ§Ã£o FundiÃ¡ria Urbana  \n"
    "âš–ï¸ Base legal: Lei 13.465/2017 e Decreto 9.310/2018  \n"
    "ğŸ¤– Powered by Google Gemini AI"
)